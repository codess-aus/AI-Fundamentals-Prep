# ğŸ¤–ğŸ’¡ Whatâ€™s Machine Learning?
Machine learning is like when computers learn from data so they can make smart guesses â€” kind of like how we learn from experience!

## ğŸ§  Whoâ€™s Involved?
Itâ€™s a team-up between:

- **Data Scientists ğŸ§ª:** They explore and clean up the data, then train the AI to recognize patterns.
- **Software Developers ğŸ’»:** They take that trained AI and plug it into apps so it can make predictions in real life!

## ğŸ” How It Works:
- Feed the AI lots of data ğŸ•ğŸ“Š
- Train it to spot patterns ğŸ§ 
- Use it in apps to make smart predictions â€” like guessing what youâ€™ll type next or spotting a cat in a photo ğŸ±

This last step is called **inferencing** â€” itâ€™s when the AI uses what it learned to make real-time decisions!

---

## ğŸ§  Where It Comes From

ML started with **math and stats** â€” using numbers and patterns to figure things out.  
The big idea? Use past data to guess what might happen next!

---

## ğŸ” Real-Life Examples

- ğŸ¦ **Ice Cream Shop**  
  An app looks at past sales + weather to guess how many ice creams will sell today.

- ğŸ©º **Doctorâ€™s Tool**  
  AI checks patient data to predict if someone might be at risk for diabetes.

- ğŸ§ **Penguin Research**  
  AI uses bird measurements to figure out which species it is â€” Adelie, Gentoo, or Chinstrap!

---

# ğŸ§ª How Machine Learning Works

ML is like building a smart calculator that turns **inputs** into **predictions**.

---
![Machine Learning](https://github.com/codess-aus/AI-Fundamentals-Prep/blob/baa2c0b1b4cfe777047df2e4f62c4dae549a32f3/docs/assets/machine-learning.png)

## ğŸ§© Step 1: Training

We give the AI a bunch of examples:

- **Features (x)** = the stuff we know (like weather, weight, flipper size)  
- **Label (y)** = the thing we want to predict (like sales, risk level, penguin type)

Example:

x = [temperature, rainfall, windspeed]
y = ice cream sales


The AI learns a function â€” letâ€™s call it **f** â€” that connects x to y:
y = f(x)


---

## ğŸ”® Step 2: Inferencing

Once trained, the AI can take *new* x values and guess y â€” this guess is called **Å·** (aka â€œy-hatâ€ ğŸ©).

Example:
Å· = 120 ice creams ğŸ¦


---

## ğŸ’¡ Summary

- **Machine Learning** = Smart guessing powered by data + math  
- It learns patterns, builds a function, and makes predictions â€” all inside your apps!

---

# ğŸ§  Types of Machine Learning

Machine learning comes in different styles â€” like different game modes ğŸ®. You pick the one that fits what you're trying to predict!

![Machine Learning Types](https://github.com/codess-aus/AI-Fundamentals-Prep/blob/ae5107c40fd5783ce6021b4b91c416a02511cf38/docs/assets/machine-learning-types.png)

---

## ğŸ“ Supervised Learning

This is when the AI learns from examples that include both:
- **Features (x)** = the stuff we know
- **Labels (y)** = the answer we want it to learn

### ğŸ”¢ Regression

Predicts a **number** â€” like how many ice creams will sell or how fast a car goes.

Examples:
- ğŸ¦ Ice cream sales based on weather
- ğŸ  House price based on size and location
- ğŸš— Car fuel efficiency based on engine size and weight

### ğŸ§ª Classification

Predicts a **category** â€” like yes/no or which type of penguin ğŸ§.

#### âœ… Binary Classification

Only **two options** â€” like true/false or yes/no.

Examples:
- ğŸ©º Is a patient at risk for diabetes?
- ğŸ’³ Will a customer default on a loan?
- ğŸ“¬ Will someone respond to a marketing email?

#### ğŸ¯ Multiclass Classification

More than **two categories**, but only one correct answer.

Examples:
- ğŸ§ Penguin species: Adelie, Gentoo, or Chinstrap
- ğŸ¬ Movie genre: Comedy, Horror, Romance, etc.

#### ğŸ·ï¸ Multilabel Classification

Sometimes, more than one label fits!

Example:
- ğŸ¥ A movie could be both Sci-Fi *and* Comedy

---

## ğŸ§© Unsupervised Learning

Here, the AI only gets **features (x)** â€” no labels. It figures out patterns on its own!

### ğŸ§  Clustering

Groups similar things together â€” like sorting socks ğŸ§¦ by color and size.

Examples:
- ğŸŒ¸ Grouping flowers by petal size and shape
- ğŸ›ï¸ Segmenting customers by shopping habits

> Clustering is like classification, but without knowing the categories ahead of time.  
> You can even use clustering to *find* categories before training a classifier!

---

## ğŸ” How It All Connects

Sometimes you:
1. Use **clustering** to find patterns
2. Label those patterns
3. Train a **classification model** to predict future labels

---
# ğŸ¤– What is Regression?

Regression is like teaching AI to **guess numbers** based on patterns it sees in past data.  
Itâ€™s part of **supervised learning**, which means the AI learns from examples that include both:
- **Features (x)** = the stuff we know (like temperature)
- **Labels (y)** = the number we want to predict (like ice cream sales)

![Supervised Training]()
---

# ğŸ§  How AI Learns to Predict: 4 Simple Steps

## 1. ğŸ² Split the Data
Break your data into two parts:
- **Training data** to teach the AI
- **Validation data** to test how well it learned

---

## 2. ğŸ§  Train the Model
Use an algorithm (like **linear regression**) to find patterns in the training data and build a model.

---

## 3. ğŸ§ª Test the Model
Use the validation data to make predictions and see how close the AIâ€™s guesses (Å·) are to the real answers (y).

---

## 4. ğŸ“ Measure & Improve
Compare the predicted answers to the real ones.  
Use metrics (like MAE, MSE, RMSE, or RÂ²) to see how accurate the model is.  
Then tweak the algorithm or settings and repeat until itâ€™s awesome!

---

And thatâ€™s how AI gets smarter with every loop! ğŸ”

---

## ğŸ“Š Visual Example

Imagine a scatter plot with dots showing how many ice creams were sold at different temperatures.  
The regression line goes through the middle of the dots, showing the trend.

---

# ğŸ§ª Part 2: Evaluating a Regression Model

Once your model is trained, itâ€™s time to test how well it works!

## ğŸ§¾ Step 1: Use the Validation Data

We saved some data earlier â€” now we use it to:
- Make predictions using the model
- Compare those predictions to the real answers

Example:

| Temperature (x) | Actual Sales (y) | Predicted Sales (Å·) |
|-----------------|------------------|----------------------|
| 52              | 0                | 2                    |
| 67              | 14               | 17                   |
| 70              | 23               | 20                   |
| 73              | 22               | 23                   |
| 78              | 26               | 28                   |
| 83              | 36               | 33                   |

---

## ğŸ“ How Do We Measure Accuracy?

### 1. **MAE (Mean Absolute Error)**  
Average of how far off the predictions were â€” no matter if too high or too low.  
ğŸ§® Example: MAE = 2.33 ice creams

### 2. **MSE (Mean Squared Error)**  
Like MAE, but it **squares** the errors â€” so big mistakes count more.  
ğŸ§® Example: MSE = 6

### 3. **RMSE (Root Mean Squared Error)**  
The square root of MSE â€” gives us the error in real units (like ice creams!).  
ğŸ§® Example: RMSE = 2.45 ice creams

### 4. **RÂ² (R-Squared)**  
Tells us how much of the pattern the model explains.  
- 1 = perfect prediction  
- 0 = no better than guessing  
ğŸ§® Example: RÂ² = 0.95 (which is awesome!)

---

## ğŸ” Keep Improving!

To get the best model, data scientists try different things:
- ğŸ§  Choose better features
- ğŸ”§ Try different algorithms
- âš™ï¸ Tweak the settings (called hyperparameters)

They repeat the process until the model is accurate enough to use in the real world!

---
# ğŸ§  Binary Classification

---

## ğŸ¯ Whatâ€™s Binary Classification?

Imagine teaching a robot to answer **yes or no** questions. Thatâ€™s binary classification. Itâ€™s like giving the robot a bunch of examples and asking it to guess if something is **true (1)** or **false (0)**.

Instead of guessing numbers (like in regression), the robot guesses **probabilities** â€” like â€œIâ€™m 70% sure this person has diabetes.â€

---

## ğŸ§ª Training the Robot

We give it data like this:

| Blood Glucose (x) | Diabetic? (y) |
|-------------------|---------------|
| 67                | 0             |
| 103               | 1             |
| 114               | 1             |
| 72                | 0             |
| 116               | 1             |
| 65                | 0             |

Then we use a smart math trick called **logistic regression** to draw an S-shaped curve (called a **sigmoid**) that helps the robot decide.

### ğŸ¤– The Robotâ€™s Brain (Function)

f(x) = P(y = 1 | x)

This means: â€œWhatâ€™s the chance y is 1 (true) given x?â€

If the robot sees a glucose level of 90 and the curve says 0.9 (90%), it predicts **yes** â€” this person probably has diabetes.

---

## ğŸ§ª Testing the Robot

We test it with new data:

| Blood Glucose (x) | Diabetic? (y) |
|-------------------|---------------|
| 66                | 0             |
| 107               | 1             |
| 112               | 1             |
| 71                | 0             |
| 87                | 1             |
| 89                | 1             |

The robot makes predictions (Å·), and we compare them to the real answers (y).

---

## ğŸ“Š Confusion Matrix (aka Scoreboard)

| Actual (y) | Predicted (Å·) | Result         |
|------------|----------------|----------------|
| 0          | 0              | âœ… True Negative |
| 1          | 1              | âœ… True Positive |
| 1          | 1              | âœ… True Positive |
| 0          | 0              | âœ… True Negative |
| 1          | 0              | âŒ False Negative |
| 1          | 1              | âœ… True Positive |

---

## ğŸ“ˆ Metrics That Matter

### ğŸ¯ Accuracy  
How often the robot gets it right:

Accuracy = (TP + TN) / Total = (3 + 2) / 6 = 0.83


### ğŸ” Recall  
How many actual diabetics the robot found:

Recall = TP / (TP + FN) = 3 / (3 + 1) = 0.75


### ğŸ¯ Precision  
How many predicted diabetics were actually diabetic:

Precision = TP / (TP + FP) = 3 / (3 + 0) = 1.0


### ğŸ§® F1-Score  
Combo of precision and recall:

F1 = (2 Ã— Precision Ã— Recall) / (Precision + Recall) = 0.86


---

## ğŸ“‰ ROC Curve & AUC

We plot how good the robot is at guessing across all thresholds. A perfect robot gets an **AUC of 1.0**. Random guessing gets **0.5**.

Our robot? **AUC = 0.875** ğŸ‰  
That means itâ€™s way better than guessing!

---

## ğŸ§  TL;DR

Binary classification is like teaching a robot to say **yes or no** based on data. We train it, test it, and score it using metrics like accuracy, recall, precision, and AUC. The better the scores, the smarter the robot!


# ğŸ§  Multiclass Classification â€“ Level Up Your ML Game ğŸ®  

## ğŸš€ Whatâ€™s the Vibe?

Multiclass classification is like giving your model the power to choose between *more than two* options. Instead of just â€œyesâ€ or â€œno,â€ itâ€™s like â€œAdelie,â€ â€œGentoo,â€ or â€œChinstrap.â€ ğŸ§ Itâ€™s part of the supervised ML squad, just like regression and binary classification. You train it, validate it, and test it â€” classic ML grind.

---

## ğŸ§Š Penguin Example (Because Penguins Are Cool)

Weâ€™ve got penguins, and weâ€™re checking out their flipper lengths (ğŸ“). Based on that, we wanna guess their species:

- `0`: Adelie  
- `1`: Gentoo  
- `2`: Chinstrap  

| Flipper Length (x) | Species (y) |
|--------------------|-------------|
| 167                | 0           |
| 172                | 0           |
| 225                | 2           |
| 197                | 1           |
| 189                | 1           |
| 232                | 2           |
| 158                | 0           |

*Note: Real-world data would have more features, but weâ€™re keeping it chill with just one.*

---

## ğŸ› ï¸ How Do We Train This Thing?

Weâ€™ve got two main ways to train a multiclass model:

### 1. One-vs-Rest (OvR)  
Train a separate binary classifier for each class. Each one says, â€œIs this my class or not?â€

- `f0(x) = P(y=0 | x)`  
- `f1(x) = P(y=1 | x)`  
- `f2(x) = P(y=2 | x)`  

Whichever one gives the highest probability wins. ğŸ†

### 2. Multinomial (aka Softmax Squad)  
One model, one function, all the probs:

```text
f(x) = [P(y=0|x), P(y=1|x), P(y=2|x)]
```

Example output: `[0.2, 0.3, 0.5]` â†’ Class 2 wins.

---

## ğŸ“Š Time to Evaluate

Letâ€™s see how our model did on some new penguins:

| Flipper Length (x) | Actual (y) | Predicted (Å·) |
|--------------------|------------|----------------|
| 165                | 0          | 0              |
| 171                | 0          | 0              |
| 205                | 2          | 1              |
| 195                | 1          | 1              |
| 183                | 1          | 1              |
| 221                | 2          | 2              |
| 214                | 2          | 2              |

### ğŸ” Confusion Matrix Vibes

| Class | TP | TN | FP | FN | Accuracy | Recall | Precision | F1-Score |
|-------|----|----|----|----|----------|--------|-----------|----------|
| 0     | 2  | 5  | 0  | 0  | 1.00     | 1.00   | 1.00      | 1.00     |
| 1     | 2  | 4  | 1  | 0  | 0.86     | 1.00   | 0.67      | 0.80     |
| 2     | 2  | 4  | 0  | 1  | 0.86     | 0.67   | 1.00      | 0.80     |

### ğŸ“ˆ Overall Stats

- **Accuracy:** (13 + 6) Ã· (13 + 6 + 1 + 1) = **0.90**  
- **Recall:** 6 Ã· (6 + 1) = **0.86**  
- **Precision:** 6 Ã· (6 + 1) = **0.86**  
- **F1-Score:** (2 Ã— 0.86 Ã— 0.86) Ã· (0.86 + 0.86) = **0.86**

---

## ğŸ‰ TL;DR

Multiclass classification = your model picking the best label from a bunch. Whether itâ€™s OvR or softmax, itâ€™s all about those probabilities. And when itâ€™s done right? You get stats that slap. ğŸ’¥


